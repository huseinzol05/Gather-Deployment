{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66632f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install unidecode\n",
    "# !pip3 install scikit-learn==0.23.2 scipy==1.5.2\n",
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/emotion/emotion-twitter-lexicon.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1115aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778ea318",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotion-twitter-lexicon.json') as fopen:\n",
    "    data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e636e19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'fear', 'happy', 'love', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(data.keys())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb53cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(string):\n",
    "    \"\"\"\n",
    "    use by any transformer model before tokenization\n",
    "    \"\"\"\n",
    "    string = unidecode(string)\n",
    "    string = re.sub('\\(dot\\)', '.', string)\n",
    "    string = (\n",
    "        re.sub(re.findall(r'\\<a(.*?)\\>', string)[0], '', string)\n",
    "        if (len(re.findall(r'\\<a (.*?)\\>', string)) > 0)\n",
    "        and ('href' in re.findall(r'\\<a (.*?)\\>', string)[0])\n",
    "        else string\n",
    "    )\n",
    "    string = re.sub(\n",
    "        r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', string\n",
    "    )\n",
    "    \n",
    "    chars = '.,/*'\n",
    "    for c in chars:\n",
    "        string = string.replace(c, f' {c} ')\n",
    "        \n",
    "    string = re.sub(r'[ ]+', ' ', string.lower()).strip().split()\n",
    "    string = [w for w in string if w[0] != '@']\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5393365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = []\n",
    "for k, v in data.items():\n",
    "    sample = random.sample(v, 10000)\n",
    "    sample = [(labels.index(k), cleaning(t)) for t in sample]\n",
    "    emotion.extend(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2d65c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 6000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotion, test_emotion = train_test_split(emotion, test_size = 0.1)\n",
    "len(train_emotion), len(test_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c80849dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:50:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sess = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e5a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sess.createDataFrame(train_emotion, ['label', 'words'])\n",
    "test_df = sess.createDataFrame(test_emotion, ['label', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233033ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    CountVectorizer(inputCol='words',\n",
    "                    outputCol='tf'),\n",
    "    IDF(inputCol='tf',\n",
    "        outputCol='tfidf'),\n",
    "    LogisticRegression(featuresCol='tfidf',\n",
    "                       regParam=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2d583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:50:56 WARN TaskSetManager: Stage 0 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:06 WARN TaskSetManager: Stage 4 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:11 WARN DAGScheduler: Broadcasting large task binary with size 1452.7 KiB\n",
      "22/02/10 14:51:11 WARN TaskSetManager: Stage 5 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:15 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:15 WARN TaskSetManager: Stage 6 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:18 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/02/10 14:51:18 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/02/10 14:51:19 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:19 WARN TaskSetManager: Stage 7 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:21 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:21 WARN TaskSetManager: Stage 8 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:21 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:21 WARN TaskSetManager: Stage 9 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:22 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:22 WARN TaskSetManager: Stage 10 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:23 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:23 WARN TaskSetManager: Stage 11 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:23 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:23 WARN TaskSetManager: Stage 12 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:24 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:24 WARN TaskSetManager: Stage 13 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:24 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:24 WARN TaskSetManager: Stage 14 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:25 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:25 WARN TaskSetManager: Stage 15 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:25 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:25 WARN TaskSetManager: Stage 16 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:26 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:26 WARN TaskSetManager: Stage 17 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:26 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:26 WARN TaskSetManager: Stage 18 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:27 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:27 WARN TaskSetManager: Stage 19 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:27 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:27 WARN TaskSetManager: Stage 20 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:27 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:27 WARN TaskSetManager: Stage 21 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:28 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:28 WARN TaskSetManager: Stage 22 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:28 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:28 WARN TaskSetManager: Stage 23 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:29 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:29 WARN TaskSetManager: Stage 24 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:29 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:29 WARN TaskSetManager: Stage 25 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:30 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:30 WARN TaskSetManager: Stage 26 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:30 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:30 WARN TaskSetManager: Stage 27 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:30 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:30 WARN TaskSetManager: Stage 28 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:31 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:31 WARN TaskSetManager: Stage 29 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:31 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:31 WARN TaskSetManager: Stage 30 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:32 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:32 WARN TaskSetManager: Stage 31 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:32 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:32 WARN TaskSetManager: Stage 32 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:33 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:33 WARN TaskSetManager: Stage 33 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:33 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:33 WARN TaskSetManager: Stage 34 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:33 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:33 WARN TaskSetManager: Stage 35 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:34 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:34 WARN TaskSetManager: Stage 36 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:34 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:34 WARN TaskSetManager: Stage 37 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:35 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:35 WARN TaskSetManager: Stage 38 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:51:35 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:35 WARN TaskSetManager: Stage 39 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:51:35 WARN DAGScheduler: Broadcasting large task binary with size 1454.1 KiB\n",
      "22/02/10 14:51:35 WARN TaskSetManager: Stage 40 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521a7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:52:09 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8918511148081394"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.transform(test_df)\n",
    "MulticlassClassificationEvaluator().evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3ea7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    CountVectorizer(inputCol='words',\n",
    "                    outputCol='tf'),\n",
    "    IDF(inputCol='tf',\n",
    "        outputCol='tfidf'),\n",
    "    NaiveBayes(smoothing=1.0, \n",
    "               modelType='multinomial', \n",
    "              featuresCol='tfidf'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da5a21b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:52:36 WARN TaskSetManager: Stage 43 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:52:40 WARN TaskSetManager: Stage 47 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:52:44 WARN DAGScheduler: Broadcasting large task binary with size 1456.6 KiB\n",
      "22/02/10 14:52:44 WARN TaskSetManager: Stage 48 contains a task of very large size (4399 KiB). The maximum recommended task size is 1000 KiB.\n",
      "22/02/10 14:52:47 WARN DAGScheduler: Broadcasting large task binary with size 1453.5 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84703fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:54:59 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7710925990576287"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.transform(test_df)\n",
    "MulticlassClassificationEvaluator().evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ff4088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:56:06 WARN TaskSetManager: Stage 86 contains a task of very large size (2672 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# !rm -rf model\n",
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1308465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83eabd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = PipelineModel.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82e2bf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 14:56:28 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7710925990576287"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_load.transform(test_df)\n",
    "MulticlassClassificationEvaluator().evaluate(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
